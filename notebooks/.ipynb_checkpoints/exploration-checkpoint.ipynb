{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Soccer Pass Prediction - Data Exploration\n",
    "\n",
    "This notebook demonstrates the pass prediction model pipeline, including:\n",
    "1. Data collection from StatsBomb\n",
    "2. Feature engineering\n",
    "3. Model training and evaluation\n",
    "4. Analysis of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.append(str(Path.cwd().parent))\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Import our modules\n",
    "from config.config import config\n",
    "from src.data.collectors.statsbomb import StatsBombCollector\n",
    "from src.data.processors.processor import PassDataProcessor\n",
    "from src.features.feature_engineering import FeatureEngineer\n",
    "from src.models.baseline import PoissonRegression, HistoricalAverageBaseline\n",
    "from src.evaluation.metrics import PassPredictionEvaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Collection\n",
    "\n",
    "Let's start by collecting some data from StatsBomb's free dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize collector\n",
    "collector = StatsBombCollector()\n",
    "\n",
    "# View available competitions\n",
    "competitions = collector.get_competitions()\n",
    "print(\"Available competitions:\")\n",
    "print(competitions[['competition_id', 'competition_name', 'season_name']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect data for a specific competition (FIFA World Cup 2018)\n",
    "competition_id = 43\n",
    "season_id = 3\n",
    "\n",
    "print(f\"Collecting data for competition {competition_id}, season {season_id}...\")\n",
    "matches, events, lineups = collector.collect_competition_data(competition_id, season_id)\n",
    "\n",
    "print(f\"\\nCollected:\")\n",
    "print(f\"- {len(matches)} matches\")\n",
    "print(f\"- {len(events)} events\")\n",
    "print(f\"- {len(lineups)} lineup records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate player pass data\n",
    "player_data = collector.aggregate_player_passes(events, matches, lineups)\n",
    "print(f\"\\nPlayer-match records: {len(player_data)}\")\n",
    "print(\"\\nSample data:\")\n",
    "player_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Processing & Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the data\n",
    "processor = PassDataProcessor(min_minutes=15, exclude_goalkeepers=True)\n",
    "processed_data, feature_matrix, feature_names = processor.process_data(player_data)\n",
    "\n",
    "print(f\"After processing: {len(processed_data)} records\")\n",
    "print(f\"\\nFeatures created: {feature_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional feature engineering\n",
    "engineer = FeatureEngineer()\n",
    "processed_data = engineer.engineer_features(processed_data, feature_set=\"intermediate\")\n",
    "\n",
    "# Update feature matrix\n",
    "feature_matrix, feature_names = processor.create_model_features(processed_data)\n",
    "print(f\"\\nEnhanced features: {len(feature_names)} total\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of passes by position\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "# Passes by position group\n",
    "ax = axes[0, 0]\n",
    "processed_data.groupby('position_group')['passes_attempted'].mean().plot(kind='bar', ax=ax)\n",
    "ax.set_title('Average Passes by Position Group')\n",
    "ax.set_xlabel('Position Group')\n",
    "ax.set_ylabel('Average Passes')\n",
    "\n",
    "# Distribution of passes\n",
    "ax = axes[0, 1]\n",
    "ax.hist(processed_data['passes_attempted'], bins=30, edgecolor='black')\n",
    "ax.set_title('Distribution of Pass Attempts')\n",
    "ax.set_xlabel('Passes Attempted')\n",
    "ax.set_ylabel('Frequency')\n",
    "\n",
    "# Passes vs Minutes Played\n",
    "ax = axes[1, 0]\n",
    "ax.scatter(processed_data['minutes_played'], processed_data['passes_attempted'], alpha=0.5)\n",
    "ax.set_title('Passes vs Minutes Played')\n",
    "ax.set_xlabel('Minutes Played')\n",
    "ax.set_ylabel('Passes Attempted')\n",
    "\n",
    "# Home vs Away performance\n",
    "ax = axes[1, 1]\n",
    "home_away = processed_data.groupby('is_home')['passes_attempted'].mean()\n",
    "home_away.plot(kind='bar', ax=ax)\n",
    "ax.set_title('Average Passes: Home vs Away')\n",
    "ax.set_xlabel('Is Home')\n",
    "ax.set_ylabel('Average Passes')\n",
    "ax.set_xticklabels(['Away', 'Home'], rotation=0)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation analysis\n",
    "numeric_cols = processed_data.select_dtypes(include=[np.number]).columns\n",
    "correlation_matrix = processed_data[numeric_cols].corr()\n",
    "\n",
    "# Top correlations with passes_attempted\n",
    "pass_correlations = correlation_matrix['passes_attempted'].sort_values(ascending=False)\n",
    "print(\"Top correlations with passes_attempted:\")\n",
    "print(pass_correlations.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for modeling\n",
    "X = feature_matrix\n",
    "y = processed_data['passes_attempted']\n",
    "exposure = processed_data['minutes_played']\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "exposure_train = exposure.iloc[X_train.index]\n",
    "exposure_test = exposure.iloc[X_test.index]\n",
    "\n",
    "print(f\"Training set: {len(X_train)} samples\")\n",
    "print(f\"Test set: {len(X_test)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train baseline model\n",
    "baseline_model = HistoricalAverageBaseline(group_columns=['position_encoded'])\n",
    "baseline_model.fit(X_train, y_train)\n",
    "y_pred_baseline = baseline_model.predict(X_test)\n",
    "\n",
    "# Train Poisson model\n",
    "poisson_model = PoissonRegression(use_exposure=True)\n",
    "poisson_model.fit(X_train, y_train, exposure=exposure_train)\n",
    "y_pred_poisson = poisson_model.predict(X_test, exposure=exposure_test)\n",
    "\n",
    "print(\"Models trained successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate models\n",
    "evaluator = PassPredictionEvaluator()\n",
    "\n",
    "baseline_metrics = evaluator.evaluate(y_test, y_pred_baseline)\n",
    "poisson_metrics = evaluator.evaluate(y_test, y_pred_poisson)\n",
    "\n",
    "# Compare results\n",
    "results_df = pd.DataFrame({\n",
    "    'Baseline': baseline_metrics,\n",
    "    'Poisson': poisson_metrics\n",
    "}).T\n",
    "\n",
    "print(\"Model Performance Comparison:\")\n",
    "print(results_df[['mae', 'rmse', 'r2', 'mape']].round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize predictions\n",
    "fig = evaluator.plot_predictions(y_test.values, y_pred_poisson, title=\"Poisson Model Predictions\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze model coefficients (Poisson)\n",
    "if hasattr(poisson_model, 'get_coefficients'):\n",
    "    coefficients = poisson_model.get_coefficients()\n",
    "    print(\"\\nPoisson Model Coefficients:\")\n",
    "    print(coefficients.sort_values('P>|z|').head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Performance by Position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate by position group\n",
    "position_groups = processed_data.iloc[X_test.index]['position_group']\n",
    "position_metrics = evaluator.evaluate_by_group(\n",
    "    y_test.values, \n",
    "    y_pred_poisson,\n",
    "    position_groups,\n",
    "    group_name='position'\n",
    ")\n",
    "\n",
    "print(\"Performance by Position:\")\n",
    "print(position_metrics[['position', 'n_samples', 'mae', 'rmse']].sort_values('mae'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot MAE by position\n",
    "plt.figure(figsize=(10, 6))\n",
    "position_metrics.plot(x='position', y='mae', kind='bar')\n",
    "plt.title('Model Error by Position Group')\n",
    "plt.xlabel('Position')\n",
    "plt.ylabel('Mean Absolute Error')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Feature Importance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate feature importance using correlation with target\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'correlation': [X_train[col].corr(y_train) for col in feature_names]\n",
    "}).sort_values('correlation', key=abs, ascending=False)\n",
    "\n",
    "print(\"Top 10 Most Important Features:\")\n",
    "print(feature_importance.head(10))\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(10, 6))\n",
    "top_features = feature_importance.head(10)\n",
    "plt.barh(range(len(top_features)), top_features['correlation'].abs())\n",
    "plt.yticks(range(len(top_features)), top_features['feature'])\n",
    "plt.xlabel('Absolute Correlation with Target')\n",
    "plt.title('Feature Importance (by Correlation)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Predictions for New Data\n",
    "\n",
    "Example of making predictions for a hypothetical player."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sample player for prediction\n",
    "sample_player = pd.DataFrame({\n",
    "    'position_encoded': [2],  # Midfielder\n",
    "    'is_home': [1],\n",
    "    'minutes_played': [90],\n",
    "    'team_strength_diff': [0.5],\n",
    "    'team_points_per_game': [2.0],\n",
    "    'opponent_points_per_game': [1.5],\n",
    "    'team_avg_goals': [2.1],\n",
    "    'opponent_avg_goals': [1.2],\n",
    "    'passes_attempted_rolling_5': [45],\n",
    "    'passes_completed_rolling_5': [38],\n",
    "    'minutes_played_rolling_5': [82],\n",
    "    'avg_pass_length': [15.5]\n",
    "})\n",
    "\n",
    "# Make prediction\n",
    "sample_exposure = pd.Series([90])\n",
    "predicted_passes = poisson_model.predict(sample_player, exposure=sample_exposure)\n",
    "\n",
    "print(f\"\\nPredicted passes for sample player: {predicted_passes[0]:.1f}\")\n",
    "\n",
    "# Get prediction interval\n",
    "if hasattr(poisson_model, 'predict_interval'):\n",
    "    pred, lower, upper = poisson_model.predict_interval(\n",
    "        sample_player, exposure=sample_exposure, alpha=0.1\n",
    "    )\n",
    "    print(f\"90% Prediction Interval: [{lower[0]:.1f}, {upper[0]:.1f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "This notebook demonstrates the Phase 1 foundation of our pass prediction model. \n",
    "\n",
    "**Potential improvements for Phase 2+:**\n",
    "1. Add tactical features (formation, playing style)\n",
    "2. Implement two-stage modeling (team volume + player share)\n",
    "3. Include opponent-specific conditioning\n",
    "4. Add game state dynamics\n",
    "5. Use more sophisticated models (XGBoost, Neural Networks)\n",
    "6. Implement tactical archetype clustering\n",
    "\n",
    "The current baseline achieves reasonable performance and provides a solid foundation for further development."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}